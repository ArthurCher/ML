{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание к лекции \"Рекуррентные сети\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 1.\n",
    "Обучите нейронную сеть решать шифр Цезаря.\n",
    "\n",
    "Что необходимо сделать:\n",
    "\n",
    "    Написать алгоритм шифра Цезаря для генерации выборки (сдвиг на К каждой буквы. Например, при сдвиге на 2 буква “А” переходит в букву “В” и тп)\n",
    "    Сделать нейронную сеть\n",
    "    Обучить ее (вход - зашифрованная фраза, выход - дешифрованная фраза)\n",
    "    Проверить качество\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Библиотеки\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'лопата'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция кодирующее слово\n",
    "def encod_cesar(word, move=2):\n",
    "    alphabet = list('абвгдеёжзийклмнопрстуфхцчшщъыьэюя')\n",
    "    word_list = list(word.lower())\n",
    "    new_word_list = []\n",
    "    \n",
    "    for char in word_list:\n",
    "        ind = alphabet.index(char) + move\n",
    "\n",
    "        if ind >= len(alphabet):\n",
    "            new_char = alphabet[ind - len(alphabet)]\n",
    "        \n",
    "        else:\n",
    "            new_char = alphabet[ind]\n",
    "        \n",
    "        new_word_list.append(new_char)\n",
    "    \n",
    "    return ''.join(new_word_list)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция декодирующее слово\n",
    "def decod_cesar(word, move=2):\n",
    "    alphabet = list('абвгдеёжзийклмнопрстуфхцчшщъыьэюя')\n",
    "    word_list = list(word.lower())\n",
    "    new_word_list = []\n",
    "    \n",
    "    for char in word_list:\n",
    "        ind = alphabet.index(char) - move\n",
    "\n",
    "        if ind < 0:\n",
    "            new_char = alphabet[ind + len(alphabet)]\n",
    "        \n",
    "        else:\n",
    "            new_char = alphabet[ind]\n",
    "        \n",
    "        new_word_list.append(new_char)\n",
    "    \n",
    "    return ''.join(new_word_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_word = encod_cesar(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "лопата\n"
     ]
    }
   ],
   "source": [
    "print(decod_cesar(new_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем массивы с данными\n",
    "\n",
    "CHARS = set('абвгдеёжзийклмнопрстуфхцчшщъыьэюя')\n",
    "INDEX_TO_CHAR = ['none'] + [w for w in CHARS]\n",
    "CHAR_TO_INDEX = {w: i for i, w in enumerate(INDEX_TO_CHAR)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 50\n",
    "X = torch.zeros((len(CHARS), 15), dtype=int)\n",
    "for i in range(len(word)):\n",
    "    for j, w in enumerate(word[i]):\n",
    "        if j >= MAX_LEN:\n",
    "            break\n",
    "        X[i, j] = CHAR_TO_INDEX.get(w, CHAR_TO_INDEX['none'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель\n",
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.embed = torch.nn.Embedding(len(CHAR_TO_INDEX), 28)\n",
    "        self.rnn = torch.nn.RNN(28, 128, batch_first=True)\n",
    "        self.linear= torch.nn.Linear(128, len(INDEX_TO_CHAR))\n",
    "        \n",
    "    def forward(self, word, state=None):\n",
    "        embed = self.embed(word)\n",
    "        o, s = self.rnn(embed)\n",
    "        out = self.linear(o)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-0b7354579751>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_passed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch {}. Time: {:.3f}, Train loss: {:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtrain_passed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Обучение не пошло... Похоже не до конца понял как заводить рекуррентные нейроные сети. Но в чем ошибка не пойму\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "\n",
    "# Обучение\n",
    "for ep in range(10):\n",
    "#     pdb.set_trace()\n",
    "    start = time.time()\n",
    "    train_loss = 0.\n",
    "    train_passed = 0\n",
    "    print(int(len(X) / 100))\n",
    "\n",
    "    for i in range(int(len(X) / 100)):\n",
    "        print('test')\n",
    "        batch = X[i * 100:(i + 1) * 100]\n",
    "        X_batch = batch[:, :-1]\n",
    "        Y_batch = batch[:, 1:].flatten()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        answers, _ = model.forward(X_batch)\n",
    "        answers = answers.view(-1, len(INDEX_TO_CHAR))\n",
    "        loss = criterion(answers, Y_batch)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_passed += 1\n",
    "    \n",
    "    print(train_passed)\n",
    "\n",
    "    print(\"Epoch {}. Time: {:.3f}, Train loss: {:.3f}\".format(ep, time.time() - start, train_loss / train_passed))\n",
    "\n",
    "# Обучение не пошло... Похоже не до конца понял как заводить рекуррентные нейроные сети. Но в чем ошибка не пойму\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 2.\n",
    "Выполнить практическую работу из лекционного ноутбука.\n",
    "\n",
    "    Построить RNN-ячейку на основе полносвязных слоев\n",
    "    Применить построенную ячейку для генерации текста с выражениями героев сериала “Симпсоны”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>number</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>timestamp_in_ms</th>\n",
       "      <th>speaking_line</th>\n",
       "      <th>character_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>raw_location_text</th>\n",
       "      <th>spoken_words</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10368</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>Lisa Simpson: Maggie, look. What's that?</td>\n",
       "      <td>235000</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Simpson Home</td>\n",
       "      <td>Maggie, look. What's that?</td>\n",
       "      <td>maggie look whats that</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10369</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "      <td>Lisa Simpson: Lee-mur. Lee-mur.</td>\n",
       "      <td>237000</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Simpson Home</td>\n",
       "      <td>Lee-mur. Lee-mur.</td>\n",
       "      <td>lee-mur lee-mur</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10370</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>Lisa Simpson: Zee-boo. Zee-boo.</td>\n",
       "      <td>239000</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Simpson Home</td>\n",
       "      <td>Zee-boo. Zee-boo.</td>\n",
       "      <td>zee-boo zee-boo</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10372</td>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "      <td>Lisa Simpson: I'm trying to teach Maggie that ...</td>\n",
       "      <td>245000</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Simpson Home</td>\n",
       "      <td>I'm trying to teach Maggie that nature doesn't...</td>\n",
       "      <td>im trying to teach maggie that nature doesnt e...</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10374</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>Lisa Simpson: It's like an ox, only it has a h...</td>\n",
       "      <td>254000</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Simpson Home</td>\n",
       "      <td>It's like an ox, only it has a hump and a dewl...</td>\n",
       "      <td>its like an ox only it has a hump and a dewlap...</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id  episode_id  number  \\\n",
       "0           0  10368          35      29   \n",
       "1           1  10369          35      30   \n",
       "2           2  10370          35      31   \n",
       "3           3  10372          35      33   \n",
       "4           4  10374          35      35   \n",
       "\n",
       "                                            raw_text  timestamp_in_ms  \\\n",
       "0           Lisa Simpson: Maggie, look. What's that?           235000   \n",
       "1                    Lisa Simpson: Lee-mur. Lee-mur.           237000   \n",
       "2                    Lisa Simpson: Zee-boo. Zee-boo.           239000   \n",
       "3  Lisa Simpson: I'm trying to teach Maggie that ...           245000   \n",
       "4  Lisa Simpson: It's like an ox, only it has a h...           254000   \n",
       "\n",
       "   speaking_line  character_id  location_id raw_character_text  \\\n",
       "0           True             9          5.0       Lisa Simpson   \n",
       "1           True             9          5.0       Lisa Simpson   \n",
       "2           True             9          5.0       Lisa Simpson   \n",
       "3           True             9          5.0       Lisa Simpson   \n",
       "4           True             9          5.0       Lisa Simpson   \n",
       "\n",
       "  raw_location_text                                       spoken_words  \\\n",
       "0      Simpson Home                         Maggie, look. What's that?   \n",
       "1      Simpson Home                                  Lee-mur. Lee-mur.   \n",
       "2      Simpson Home                                  Zee-boo. Zee-boo.   \n",
       "3      Simpson Home  I'm trying to teach Maggie that nature doesn't...   \n",
       "4      Simpson Home  It's like an ox, only it has a hump and a dewl...   \n",
       "\n",
       "                                     normalized_text  word_count  \n",
       "0                             maggie look whats that         4.0  \n",
       "1                                    lee-mur lee-mur         2.0  \n",
       "2                                    zee-boo zee-boo         2.0  \n",
       "3  im trying to teach maggie that nature doesnt e...        24.0  \n",
       "4  its like an ox only it has a hump and a dewlap...        18.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# данные\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['maggie look whats that',\n",
       " 'lee-mur lee-mur',\n",
       " 'zee-boo zee-boo',\n",
       " 'im trying to teach maggie that nature doesnt end with the barnyard i want her to have all the advantages that i didnt have',\n",
       " 'its like an ox only it has a hump and a dewlap hump and dew-lap hump and dew-lap',\n",
       " 'you know his blood type how romantic',\n",
       " 'oh yeah whats my shoe size',\n",
       " 'ring',\n",
       " 'yes dad',\n",
       " 'ooh look maggie what is that do-dec-ah-edron dodecahedron']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases = df['normalized_text'].tolist()\n",
    "phrases[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [[c for c in ph] for ph in phrases if type(ph) is str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARS = set('abcdefghijklmnopqrstuvwxyz ')\n",
    "INDEX_TO_CHAR = ['none'] + [w for w in CHARS]\n",
    "CHAR_TO_INDEX = {w: i for i, w in enumerate(INDEX_TO_CHAR)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 50\n",
    "X = torch.zeros((len(text), MAX_LEN), dtype=int)\n",
    "for i in range(len(text)):\n",
    "    for j, w in enumerate(text[i]):\n",
    "        if j >= MAX_LEN:\n",
    "            break\n",
    "        X[i, j] = CHAR_TO_INDEX.get(w, CHAR_TO_INDEX['none'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сеть\n",
    "\n",
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.embed = torch.nn.Embedding(len(CHAR_TO_INDEX), 28)\n",
    "        self.rnn = torch.nn.RNN(28, 128, batch_first=True)\n",
    "        self.linear= torch.nn.Linear(128, len(INDEX_TO_CHAR))\n",
    "        \n",
    "    def forward(self, word, state=None):\n",
    "        embed = self.embed(word)\n",
    "        o, s = self.rnn(embed)\n",
    "        out = self.linear(o)\n",
    "\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция генерации последовательности\n",
    "\n",
    "def generate_sentence():\n",
    "    sentence = ['h', 'e', 'l', 'l', 'o']\n",
    "    \n",
    "    x = torch.zeros((1, len(sentence)), dtype=int)\n",
    "    \n",
    "    for j, w in enumerate(sentence):\n",
    "        if j >= MAX_LEN:\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            x[0, j] = CHAR_TO_INDEX.get(w, CHAR_TO_INDEX['none'])\n",
    "#     s = None\n",
    "    \n",
    "    for i in range(MAX_LEN):\n",
    "        o = model(x)\n",
    "        w = torch.argmax(o[-1, -1, :], keepdim=True)\n",
    "        x = torch.cat([x, w.unsqueeze(0)], axis=1)\n",
    "        ww = INDEX_TO_CHAR[w]\n",
    "        \n",
    "        if ww == 'none':\n",
    "            break\n",
    "            \n",
    "        sentence.append(ww)\n",
    "    \n",
    "    print(' '.join(sentence))\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Time: 6.714, Train loss: 2.095\n",
      "h e l l o   t   t   t   t   t   t   t   t   t   t   t   t   t   t   t   t   t   t   t   t   t   t   t   t   t\n",
      "Epoch 1. Time: 6.384, Train loss: 1.814\n",
      "h e l l o   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t\n",
      "Epoch 2. Time: 6.527, Train loss: 1.727\n",
      "h e l l o   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t\n",
      "Epoch 3. Time: 6.246, Train loss: 1.677\n",
      "h e l l o   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t\n",
      "Epoch 4. Time: 8.806, Train loss: 1.642\n",
      "h e l l o   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t\n",
      "Epoch 5. Time: 8.029, Train loss: 1.617\n",
      "h e l l o   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t\n",
      "Epoch 6. Time: 8.762, Train loss: 1.596\n",
      "h e l l o   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t\n",
      "Epoch 7. Time: 8.480, Train loss: 1.579\n",
      "h e l l o   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t\n",
      "Epoch 8. Time: 9.505, Train loss: 1.564\n",
      "h e l l o   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t\n",
      "Epoch 9. Time: 7.389, Train loss: 1.551\n",
      "h e l l o   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t h e   t\n"
     ]
    }
   ],
   "source": [
    "# Обучение и генерация фраз\n",
    "\n",
    "for ep in range(10):\n",
    "    start = time.time()\n",
    "    train_loss = 0.\n",
    "    train_passed = 0\n",
    "\n",
    "    for i in range(int(len(X) / 100)):\n",
    "        batch = X[i * 100:(i + 1) * 100]\n",
    "        X_batch = batch[:, :-1]\n",
    "        Y_batch = batch[:, 1:].flatten()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        answers = model.forward(X_batch)\n",
    "        answers = answers.view(-1, len(INDEX_TO_CHAR))\n",
    "        loss = criterion(answers, Y_batch)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_passed += 1\n",
    "\n",
    "    print(\"Epoch {}. Time: {:.3f}, Train loss: {:.3f}\".format(ep, time.time() - start, train_loss / train_passed))\n",
    "    generate_sentence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но опять же почему-то не завелась..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
